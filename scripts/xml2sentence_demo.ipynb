{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML 2 Sentence Format Demo\n",
    "\n",
    "This notebook is for showing how to convert the XML format to sentences for training in other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* loaded all libraries\n"
     ]
    }
   ],
   "source": [
    "import medtator_kits as mtk\n",
    "import sentence_kits as stk\n",
    "\n",
    "# force reload everything in mtk\n",
    "import importlib\n",
    "importlib.reload(mtk)\n",
    "importlib.reload(stk)\n",
    "\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# for data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for display nicer\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# load sentence detection\n",
    "import pysbd\n",
    "# load spacy and config the sentencizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "# Create a Tokenizer with the default settings for English\n",
    "# including punctuation rules and exceptions\n",
    "tokenizer = nlp.tokenizer\n",
    "\n",
    "print('* loaded all libraries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* checking path ../sample/ENTITY_RELATION_TASK/ann_xml/Annotator_A/\n",
      "* parsed XML file ../sample/ENTITY_RELATION_TASK/ann_xml/Annotator_A/A_doc2.txt.xml\n",
      "* parsed XML file ../sample/ENTITY_RELATION_TASK/ann_xml/Annotator_A/A_doc3.txt.xml\n",
      "* parsed XML file ../sample/ENTITY_RELATION_TASK/ann_xml/Annotator_A/A_doc1.txt.xml\n",
      "* parsed XML file ../sample/ENTITY_RELATION_TASK/ann_xml/Annotator_A/A_doc4.txt.xml\n",
      "* checked 4 files\n",
      "* found 4 XML files\n",
      "* skipped 0 non-XML files\n",
      "{'total_files': 4, 'total_xml_files': 4, 'total_other_files': 0, 'total_tags': 62}\n"
     ]
    }
   ],
   "source": [
    "path = '../sample/ENTITY_RELATION_TASK/ann_xml/Annotator_A/'\n",
    "rst = mtk.parse_xmls(path)\n",
    "print(rst['stat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse and convert format\n",
    "\n",
    "We want to convert the text into a sentence-based format for downstream task (e.g., training relation extraction), so first of all, a sentencizer and a tokenizer are needed.\n",
    "You can use any libraries for this purpose.\n",
    "\n",
    "For here, we use `pySBD` for [sentence boundary detection](https://github.com/nipunsadvilkar/pySBD).\n",
    "\n",
    "```Python\n",
    "import pysbd\n",
    "text = \"My name is Jonas E. Smith. Please turn to p. 55.\"\n",
    "seg = pysbd.Segmenter(language=\"en\", clean=False, char_span=True)\n",
    "print(seg.segment(text))\n",
    "# [TextSpan(sent='My name is Jonas E. Smith. ', start=0, end=27), TextSpan(sent='Please turn to p. 55.', start=27, end=48)]\n",
    "```\n",
    "\n",
    "and we use `spaCy`'s [Tokenizer](https://spacy.io/api/tokenizer).\n",
    "\n",
    "```Python\n",
    "\n",
    "# Use Sentencizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "tokenizer = nlp.tokenizer\n",
    "tokens = tokenizer(\"This is a sentence for tokens.\")\n",
    "sentence_tokens = list(map(lambda v: v.text, tokens))\n",
    "sentence_tokens\n",
    "# ['This', 'is', 'a', 'sentence', 'for', 'tokens', '.']\n",
    "```\n",
    "\n",
    "Second, we need a way to map the spans to token index.\n",
    "In the `sentence_kits.py`, we implemented a function `update_ents_token_index()` for this purpose. It uses the spans of a tag to check whether overlapped with any tokens of a sentence.\n",
    "The function `update_ents_token_index()` will update the entities by adding a new property `token_index` which is a list of token indexes.\n",
    "\n",
    "For more details, please check the follwoing section *Sentence-based format* and the source code in `sentence_kits.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence-based format\n",
    "\n",
    "In the following demo, we will convert each XML file into a sentence-based format, which looks like the following:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"text\": \"The full text of the file\",\n",
    "    \"sentence_tags\": [{\n",
    "        \"sentence\": \"this is a sentence.\",\n",
    "        \"sentence_tokens\": [\"this\", \"is\", \"a\" \"sentence\", \".\"],\n",
    "        \"spans\": [start, end],\n",
    "        \"entities\": {\n",
    "            \"A1\": {\n",
    "                \"id\": \"A1\",\n",
    "                \"text\": \"this\",\n",
    "                \"token_index\": [0, 0]\n",
    "                // other properties\n",
    "            },\n",
    "            \"A2\": {\n",
    "                \"id\": \"A2\",\n",
    "                \"text\": \"a sentence\",\n",
    "                \"token_index\": [2, 3]\n",
    "                // other properties\n",
    "            }\n",
    "        },\n",
    "        \"relations\": {\n",
    "            \"R1\": {\n",
    "                \"id\": \"R1\",\n",
    "                \"link_EAID\": \"A1\", // this\n",
    "                \"link_EBID\": \"A2\", // a sentence\n",
    "            }\n",
    "        }\n",
    "    }]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* got 4 ann_sents\n"
     ]
    }
   ],
   "source": [
    "# let's check the sentence-based format for the given samples\n",
    "ann_sents = stk.convert_anns_to_sentags(rst['anns'])\n",
    "print(\"* got %s ann_sents\" % (len(ann_sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** A_doc2.txt.xml 3 sent(s) ******************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `Medical` | `history` | `included` | `<span style=\"color:#9EBEBE;background:black;\">allergies</span>` | `,` | `<span style=\"color:#CED9AC;background:black;\">asthma</span>` | `and` | `Clostridium` | `difficile` | `(` | `c.dif` | `)` | `.`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `Patient` | `had` | `<span style=\"color:#D9F99C;background:black;\">allergies</span>` | `to` | `medications` | `,` | `food` | `or` | `other` | `products` | `.`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b style=\"color:red;\">HAS REL</b>:[ `On` | `28Jan2021` | `18:30` | `,` | `the` | `patient` | `experienced` | `<span style=\"color:#EDE99C;background:black;\">mild</span>` | `<span style=\"color:#F9ABAA;background:black;\">nausea</span>` | `.`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** A_doc3.txt.xml 3 sent(s) ******************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `Injector` | `was` | `distracted` | `or` | `not` | `fully` | `trained` | `,` | `and` | `the` | `patient` | `felt` | `<span style=\"color:#DCA9F9;background:black;\">pain</span>` | `<span style=\"color:#DCA9F9;background:black;\">with</span>` | `<span style=\"color:#DCA9F9;background:black;\">the</span>` | `<span style=\"color:#DCA9F9;background:black;\">needle</span>` | `and` | `<span style=\"color:#FFEFEB;background:black;\">pain</span>` | `while` | `the` | `liquid` | `of` | `the` | `vaccine` | `was` | `entering` | `to` | `the` | `arm` | `.`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b style=\"color:red;\">HAS REL</b>:[ `The` | `day` | `after` | `the` | `arm` | `was` | `<span style=\"color:#EBBFE9;background:black;\">very</span>` | `<span style=\"color:#EFE9AC;background:black;\">sore</span>` | `<span style=\"color:#EFE9AC;background:black;\">,</span>` | `<span style=\"color:#EFE9AC;background:black;\">red</span>` | `<span style=\"color:#EFE9AC;background:black;\">and</span>` | `<span style=\"color:#EFE9AC;background:black;\">bruised</span>` | `,` | `but` | `he` | `thought` | `it` | `is` | `because` | `the` | `administration` | `of` | `the` | `needle` | `,` | `not` | `a` | `side` | `effect` | `of` | `the` | `vaccine` | `.`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `Unfortunately` | `,` | `had` | `an` | `incompetent` | `injector` | `who` | `gave` | `him` | `a` | `<span style=\"color:#DF9CBB;background:black;\">painful</span>` | `experience` | `with` | `the` | `injection` | `and` | `the` | `realize` | `of` | `the` | `vaccine` | `.`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** A_doc1.txt.xml 5 sent(s) ******************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b style=\"color:red;\">HAS REL</b>:[ `The` | `consumer` | `reported` | `receiving` | `her` | `first` | `injection` | `of` | `the` | `Pfizer` | `BioNTech` | `COVID-19` | `vaccine` | `2` | `weeks` | `ago` | `and` | `the` | `only` | `side` | `effect` | `she` | `experienced` | `was` | `some` | `<span style=\"color:#FBAAAF;background:black;\">mild</span>` | `<span style=\"color:#D9E9AA;background:black;\">pain</span>` | `at` | `the` | `site` | `of` | `injection` | `that` | `lasted` | `only` | `a` | `day` | `.`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b style=\"color:red;\">HAS REL</b>:[ `The` | `consumer` | `reports` | `the` | `<span style=\"color:#BFAF9C;background:black;\">pain</span>` | `was` | `<span style=\"color:#CDFFAF;background:black;\">similar</span>` | `to` | `what` | `she` | `experienced` | `in` | `the` | `past` | `after` | `a` | `flu` | `shot` | `and` | `a` | `shingles` | `shot` | `.`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `The` | `consumer` | `reported` | `when` | `she` | `was` | `told` | `by` | `people` | `where` | `she` | `received` | `her` | `injection` | `that` | `people` | `<span style=\"color:#ACEDD9;background:black;\">react</span>` | `<span style=\"color:#ACEDD9;background:black;\">more</span>` | `to` | `the` | `second` | `shot` | `compared` | `to` | `the` | `first` | `,` | `and` | `younger` | `people` | `<span style=\"color:#D9FCCA;background:black;\">react</span>` | `<span style=\"color:#D9FCCA;background:black;\">more</span>` | `to` | `the` | `injections` | `that` | `older` | `people` | `for` | `side` | `effects` | `like` | `<span style=\"color:#DED9DE;background:black;\">headache</span>` | `and` | `<span style=\"color:#BFD9BB;background:black;\">fever</span>` | `.`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `The` | `consumer` | `also` | `stated` | `,` | `\"` | `Here` | `is` | `the` | `question` | `,` | `my` | `mother` | `who` | `is` | `going` | `to` | `be` | `97` | `and` | `I` | `,` | `who` | `is` | `going` | `to` | `be` | `70` | `received` | `the` | `first` | `Pfizer` | `Shot` | `a` | `couple` | `(` | `Covid-19` | `Vaccine` | `)` | `of` | `weeks` | `ago` | `,` | `we` | `are` | `due` | `for` | `the` | `second` | `shot` | `for` | `next` | `Thursday` | `actually` | `and` | `I` | `was` | `told` | `we` | `had` | `no` | `side` | `effects` | `at` | `all` | `thank` | `goodness` | `just` | `the` | `<span style=\"color:#ADABAA;background:black;\">sore</span>` | `<span style=\"color:#ADABAA;background:black;\">arm</span>` | `.` | `Now` | `I` | `was` | `told` | `for` | `the` | `second` | `shot` | `that` | `you` | `usually` | `do` | `get` | `some` | `kind` | `of` | `side` | `effects` | `,` | `so` | `my` | `question` | `is` | `my` | `mother` | `and` | `I` | `taking` | `a` | `shot` | `at` | `the` | `same` | `time` | `,` | `I` | `live` | `along` | `with` | `her` | `and` | `should` | `I` | `have` | `somebody` | `with` | `me` | `just` | `what` | `are` | `the` | `odds` | `we` | `are` | `going` | `to` | `have` | `side` | `effects` | `from` | `the` | `second` | `shot` | `,` | `I` | `guess` | `that` | `'s` | `my` | `question` | `.` | `\"`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b style=\"color:red;\">HAS REL</b>:[ `The` | `outcome` | `of` | `the` | `event` | `<span style=\"color:#CFDDFF;background:black;\">mild</span>` | `<span style=\"color:#A9B9BF;background:black;\">pain</span>` | `at` | `the` | `site` | `of` | `injection` | `was` | `recovered` | `while` | `other` | `event` | `was` | `unknown` | `.` | ` `]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** A_doc4.txt.xml 18 sent(s) ******************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `4/10/21` | `Patient` | `presented` | `to` | `Urgent` | `Care` | `with` | `<span style=\"color:#BCCCBC;background:black;\">Arm</span>` | `<span style=\"color:#BCCCBC;background:black;\">Pain</span>` | `(` | `<span style=\"color:#F99AA9;background:black;\">left</span>` | `<span style=\"color:#F99AA9;background:black;\">arm</span>` | `<span style=\"color:#F99AA9;background:black;\">painful</span>` | `and` | `tingly` | `since` | `COVID` | `shot` | `4/8` | `;` | `now` | `<span style=\"color:#BEEDCC;background:black;\">pain</span>` | `is` | `<span style=\"color:#BACAFB;background:black;\">different</span>` | `and` | `there` | `is` | `a` | `lump` | `on` | `her` | `forearm` | `she` | `can` | `feel` | `)` | `.` | ` \n",
       "\n",
       "`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `1` | `.` | `<span style=\"color:#ED9BFB;background:black;\">Left</span>` | `<span style=\"color:#ED9BFB;background:black;\">arm</span>` | `<span style=\"color:#ED9BFB;background:black;\">pain</span>` | `-` | `<span style=\"color:#9DABAB;background:black;\">tender</span>` | `<span style=\"color:#9DABAB;background:black;\">nodule</span>` | `L` | `forearm` | `,` | `will` | `get` | `US` | `due` | `to` | `recent` | `birth` | `,` | `Johnson` | `and` | `Johnson` | `vaccine` | `,` | `FH` | `of` | `DVT` | `,` | `to` | `r` | `/` | `o` | `DVT` | `causing` | `the` | `lump` | `,` | `await` | `results` | `.` | ` `]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `-` | `USV` | `VENOUS` | `UPPER` | `EXTREMITY` | `DUPLEX` | `LEFT` | `;` | `Future` | `  ` | `2` | `.` | `<span style=\"color:#ABBDAA;background:black;\">Paresthesia</span>` | `of` | `left` | `arm` | `-` | `site` | `of` | `reported` | `injection` | `and` | `superficial` | `induration` | `1.5` | `cm` | `from` | `acromion` | `process` | `,` | `suspect` | `SIRVA` | `due` | `to` | `sit` | `of` | `administration` | `of` | `vaccine` | `,` | `recommend` | `symptomatic` | `care` | `with` | `warm` | `compresses` | `,` | `gentle` | `massage` | `if` | `benefit` | `noted` | `,` | `pt` | `is` | `breastfeeding` | `so` | `recommend` | `local` | `care` | `at` | `this` | `time` | `,` | `consider` | `PT` | `,` | `pt` | `declines` | `at` | `this` | `time` | `as` | `she` | `will` | `be` | `on` | `vacation` | `next` | `week` | `.` | ` `]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `She` | `has` | `a` | `<span style=\"color:#DEBFDA;background:black;\">very</span>` | `<span style=\"color:#DEBFDA;background:black;\">slight</span>` | `<span style=\"color:#BABCEB;background:black;\">headache</span>` | `which` | `has` | `been` | `present` | `since` | `the` | `day` | `she` | `received` | `the` | `vaccine` | `,` | `currently` | `2/10` | `without` | `vision` | `or` | `other` | `neurologic` | `concerns` | `.` | ` `]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `No` | `abdominal` | `<span style=\"color:#EBDEEA;background:black;\">pain</span>` | `.` | ` `]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `Advised` | `return` | `if` | `she` | `develops` | `worsening` | `<span style=\"color:#9EDCBC;background:black;\">headache</span>` | `or` | `new` | `neurologic` | `symptoms` | `.` | `  \n",
       "\n",
       "`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `Patient` | `complained` | `of` | `new` | `onset` | `left` | `lower` | `lateral` | `breast` | `<span style=\"color:#99DEAA;background:black;\">pain</span>` | `and` | `lump` | `starting` | `today` | `.` | ` `]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `She` | `does` | `have` | `a` | `tender` | `fullness` | `on` | `exam` | `but` | `no` | `<span style=\"color:#C9D99B;background:black;\">redness</span>` | `or` | `visible` | `swelling` | `,` | `she` | `is` | `nontoxic` | `and` | `well` | `-` | `appearing` | `without` | `fever` | `.` | ` `]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `She` | `was` | `seen` | `here` | `last` | `week` | `for` | `<span style=\"color:#9ACDDE;background:black;\">left</span>` | `<span style=\"color:#9ACDDE;background:black;\">arm</span>` | `<span style=\"color:#9ACDDE;background:black;\">pain</span>` | `/` | `nodule` | `/` | `paresthesa` | `following` | `her` | `Johnson` | `&` | `Johnson` | `vaccine` | `.`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b style=\"color:red;\">HAS REL</b>:[ `She` | `also` | `reported` | `a` | `<span style=\"color:#CCFE9D;background:black;\">slight</span>` | `<span style=\"color:#FCFFEE;background:black;\">headache</span>` | `that` | `was` | `present` | `since` | `day` | `of` | `vaccine` | `.`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `An` | `US` | `was` | `performed` | `and` | `showed` | `a` | `<span style=\"color:#EAD9AE;background:black;\">left</span>` | `<span style=\"color:#EAD9AE;background:black;\">cephalic</span>` | `<span style=\"color:#EAD9AE;background:black;\">vein</span>` | `<span style=\"color:#EAD9AE;background:black;\">thrombus</span>` | `of` | `LUE` | `.`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `She` | `then` | `called` | `in` | `with` | `<span style=\"color:#CDADCB;background:black;\">left</span>` | `<span style=\"color:#CDADCB;background:black;\">breast</span>` | `<span style=\"color:#CDADCB;background:black;\">pain</span>` | `<span style=\"color:#CDADCB;background:black;\">/</span>` | `<span style=\"color:#CDADCB;background:black;\">swelling</span>` | `and` | `was` | `directed` | `to` | `the` | `ED` | `for` | `evaluation` | `of` | `possible` | `blood` | `clot` | `.`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `Today` | `,` | `patient` | `presents` | `states` | `he` | `feels` | `\"` | `<span style=\"color:#BFFEAD;background:black;\">a</span>` | `<span style=\"color:#BFFEAD;background:black;\">lot</span>` | `<span style=\"color:#BFFEAD;background:black;\">better</span>` | `\"` | `.`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `Regarding` | `the` | `<span style=\"color:#FED99D;background:black;\">left</span>` | `<span style=\"color:#FED99D;background:black;\">breast</span>` | `<span style=\"color:#FED99D;background:black;\">lump</span>` | `,` | `<span style=\"color:#AFAE9E;background:black;\">redness</span>` | `,` | `<span style=\"color:#FCBFCB;background:black;\">swelling</span>` | `she` | `states` | `this` | `has` | `<span style=\"color:#EFE9DD;background:black;\">completely</span>` | `<span style=\"color:#EFE9DD;background:black;\">resolved</span>` | `.`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `Regarding` | `her` | `left` | `arm` | `symptoms` | `,` | `she` | `states` | `the` | `numbness` | `/` | `tingling` | `has` | `nearly` | `resolved` | `;` | `she` | `will` | `occasionally` | `get` | `a` | `very` | `<span style=\"color:#AAF9EE;background:black;\">mild</span>` | `tingling` | `in` | `her` | `4th/5th` | `fingers` | `that` | `resolves` | `after` | `a` | `few` | `seconds` | `.`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "ENT ONLY:[ `She` | `denies` | `<span style=\"color:#9FCBA9;background:black;\">pain</span>` | `or` | `swelling` | `of` | `the` | `arm` | `.`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b style=\"color:red;\">HAS REL</b>:[ `Her` | `<span style=\"color:#A9CEED;background:black;\">mild</span>` | `<span style=\"color:#AF9BB9;background:black;\">headache</span>` | `continues` | `since` | `the` | `vaccine` | `but` | `is` | `somewhat` | `improved` | `.`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b style=\"color:red;\">HAS REL</b>:[ `She` | `denies` | `worsening` | `or` | `<span style=\"color:#9D9FDA;background:black;\">severe</span>` | `<span style=\"color:#AFBEDB;background:black;\">headache</span>` | `;` | `denies` | `<span style=\"color:#BADA9A;background:black;\">vision</span>` | `<span style=\"color:#BADA9A;background:black;\">changes</span>` | `,` | `<span style=\"color:#9DFBEC;background:black;\">dizziness</span>` | `,` | `<span style=\"color:#DBCBAC;background:black;\">lightheadedness</span>` | `,` | `<span style=\"color:#BACBAD;background:black;\">speech</span>` | `<span style=\"color:#BACBAD;background:black;\">difficulty</span>` | `,` | `etc` | `.` | `  \n",
       "\n",
       "`]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's show how the results look like\n",
    "# the following code just for reference, you can use and modify for your purpose\n",
    "for ann_idx, (ann, ann_sent) in enumerate(zip(rst['anns'], ann_sents)):\n",
    "    print('*' * 30, ann['_filename'], len(ann_sent['sentence_tags']), 'sent(s)', '*' * 30)\n",
    "    for sentag in ann_sent['sentence_tags']:\n",
    "        if len(sentag['relations'])>0: sign = '<b style=\"color:red;\">HAS REL</b>:'\n",
    "        else: sign = 'ENT ONLY:'\n",
    "\n",
    "        # parse the tokens\n",
    "        tokens = copy.copy(sentag['sentence_tokens'])\n",
    "        # print(tokens)\n",
    "        for ent in sentag['entities'].values():\n",
    "            color = ''.join([random.choice('9ABCDEF') for j in range(6)])\n",
    "            for idx in range(ent['token_index'][0], ent['token_index'][1] + 1):\n",
    "                tokens[idx] = '<span style=\"color:#%s;background:black;\">%s</span>' % (\n",
    "                    color,\n",
    "                    tokens[idx]\n",
    "                )\n",
    "        display(HTML(sign + \"[ `\" + \"` | `\".join(tokens) + \"`]\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, each token is shown in a pair of ``. \n",
    "The entities are located by the token index.\n",
    "\n",
    "Then, we can use this way to explore the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 1: Adverse event severity relation detection\n",
    "\n",
    "In this demo, we use the toolkits in this folder to make a tiny dataset for training a model for detection severity of adverse event.\n",
    "\n",
    "Please run the above cells to load the sample dataset.\n",
    "After loading, all documents are loaded into a variable `ann_sents`.\n",
    "Now, let's convert the data to a tiny training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset\n",
    "\n",
    "First of all, we can create a tiny dataset from the annotated corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* got the dataset 19 records!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AE</th>\n",
       "      <th>SVRT</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ann_idx</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'tag': 'AE', 'spans': [[689, 695]], 'text': '...</td>\n",
       "      <td>{'tag': 'SVRT', 'spans': [[684, 688]], 'text':...</td>\n",
       "      <td>On 28Jan2021 18:30, the patient experienced mi...</td>\n",
       "      <td>[On, 28Jan2021, 18:30, ,, the, patient, experi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'tag': 'AE', 'spans': [[1211, 1232]], 'text':...</td>\n",
       "      <td>{'tag': 'SVRT', 'spans': [[1206, 1210]], 'text...</td>\n",
       "      <td>The day after the arm was very sore, red and b...</td>\n",
       "      <td>[The, day, after, the, arm, was, very, sore, ,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'tag': 'AE', 'spans': [[696, 700]], 'text': '...</td>\n",
       "      <td>{'tag': 'SVRT', 'spans': [[691, 695]], 'text':...</td>\n",
       "      <td>The consumer reported receiving her first inje...</td>\n",
       "      <td>[The, consumer, reported, receiving, her, firs...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'tag': 'AE', 'spans': [[775, 779]], 'text': '...</td>\n",
       "      <td>{'tag': 'SVRT', 'spans': [[784, 791]], 'text':...</td>\n",
       "      <td>The consumer reports the pain was similar to w...</td>\n",
       "      <td>[The, consumer, reports, the, pain, was, simil...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'tag': 'AE', 'spans': [[1102, 1110]], 'text':...</td>\n",
       "      <td>{'tag': 'SVRT', 'spans': [[1033, 1043]], 'text...</td>\n",
       "      <td>The consumer reported when she was told by peo...</td>\n",
       "      <td>[The, consumer, reported, when, she, was, told...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'tag': 'AE', 'spans': [[1102, 1110]], 'text':...</td>\n",
       "      <td>{'tag': 'SVRT', 'spans': [[961, 971]], 'text':...</td>\n",
       "      <td>The consumer reported when she was told by peo...</td>\n",
       "      <td>[The, consumer, reported, when, she, was, told...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'tag': 'AE', 'spans': [[1115, 1120]], 'text':...</td>\n",
       "      <td>{'tag': 'SVRT', 'spans': [[1033, 1043]], 'text...</td>\n",
       "      <td>The consumer reported when she was told by peo...</td>\n",
       "      <td>[The, consumer, reported, when, she, was, told...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'tag': 'AE', 'spans': [[1115, 1120]], 'text':...</td>\n",
       "      <td>{'tag': 'SVRT', 'spans': [[961, 971]], 'text':...</td>\n",
       "      <td>The consumer reported when she was told by peo...</td>\n",
       "      <td>[The, consumer, reported, when, she, was, told...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'tag': 'AE', 'spans': [[1789, 1793]], 'text':...</td>\n",
       "      <td>{'tag': 'SVRT', 'spans': [[1784, 1788]], 'text...</td>\n",
       "      <td>The outcome of the event mild pain at the site...</td>\n",
       "      <td>[The, outcome, of, the, event, mild, pain, at,...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'tag': 'AE', 'spans': [[46, 54]], 'text': 'Ar...</td>\n",
       "      <td>{'tag': 'SVRT', 'spans': [[118, 127]], 'text':...</td>\n",
       "      <td>4/10/21 Patient presented to Urgent Care with ...</td>\n",
       "      <td>[4/10/21, Patient, presented, to, Urgent, Care...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'tag': 'AE', 'spans': [[56, 72]], 'text': 'le...</td>\n",
       "      <td>{'tag': 'SVRT', 'spans': [[118, 127]], 'text':...</td>\n",
       "      <td>4/10/21 Patient presented to Urgent Care with ...</td>\n",
       "      <td>[4/10/21, Patient, presented, to, Urgent, Care...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'tag': 'AE', 'spans': [[110, 114]], 'text': '...</td>\n",
       "      <td>{'tag': 'SVRT', 'spans': [[118, 127]], 'text':...</td>\n",
       "      <td>4/10/21 Patient presented to Urgent Care with ...</td>\n",
       "      <td>[4/10/21, Patient, presented, to, Urgent, Care...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'tag': 'AE', 'spans': [[2221, 2229]], 'text':...</td>\n",
       "      <td>{'tag': 'SVRT', 'spans': [[2209, 2220]], 'text...</td>\n",
       "      <td>She has a very slight headache which has been ...</td>\n",
       "      <td>[She, has, a, very, slight, headache, which, h...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'tag': 'AE', 'spans': [[3713, 3721]], 'text':...</td>\n",
       "      <td>{'tag': 'SVRT', 'spans': [[3706, 3712]], 'text...</td>\n",
       "      <td>She also reported a slight headache that was p...</td>\n",
       "      <td>[She, also, reported, a, slight, headache, tha...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'tag': 'AE', 'spans': [[4325, 4341]], 'text':...</td>\n",
       "      <td>{'tag': 'SVRT', 'spans': [[4381, 4400]], 'text...</td>\n",
       "      <td>Regarding the left breast lump, redness, swell...</td>\n",
       "      <td>[Regarding, the, left, breast, lump, ,, rednes...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'tag': 'AE', 'spans': [[4343, 4350]], 'text':...</td>\n",
       "      <td>{'tag': 'SVRT', 'spans': [[4381, 4400]], 'text...</td>\n",
       "      <td>Regarding the left breast lump, redness, swell...</td>\n",
       "      <td>[Regarding, the, left, breast, lump, ,, rednes...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'tag': 'AE', 'spans': [[4352, 4360]], 'text':...</td>\n",
       "      <td>{'tag': 'SVRT', 'spans': [[4381, 4400]], 'text...</td>\n",
       "      <td>Regarding the left breast lump, redness, swell...</td>\n",
       "      <td>[Regarding, the, left, breast, lump, ,, rednes...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'tag': 'AE', 'spans': [[5416, 5424]], 'text':...</td>\n",
       "      <td>{'tag': 'SVRT', 'spans': [[5411, 5415]], 'text...</td>\n",
       "      <td>Her mild headache continues since the vaccine ...</td>\n",
       "      <td>[Her, mild, headache, continues, since, the, v...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'tag': 'AE', 'spans': [[5510, 5518]], 'text':...</td>\n",
       "      <td>{'tag': 'SVRT', 'spans': [[5503, 5509]], 'text...</td>\n",
       "      <td>She denies worsening or severe headache; denie...</td>\n",
       "      <td>[She, denies, worsening, or, severe, headache,...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   AE  \\\n",
       "0   {'tag': 'AE', 'spans': [[689, 695]], 'text': '...   \n",
       "1   {'tag': 'AE', 'spans': [[1211, 1232]], 'text':...   \n",
       "2   {'tag': 'AE', 'spans': [[696, 700]], 'text': '...   \n",
       "3   {'tag': 'AE', 'spans': [[775, 779]], 'text': '...   \n",
       "4   {'tag': 'AE', 'spans': [[1102, 1110]], 'text':...   \n",
       "5   {'tag': 'AE', 'spans': [[1102, 1110]], 'text':...   \n",
       "6   {'tag': 'AE', 'spans': [[1115, 1120]], 'text':...   \n",
       "7   {'tag': 'AE', 'spans': [[1115, 1120]], 'text':...   \n",
       "8   {'tag': 'AE', 'spans': [[1789, 1793]], 'text':...   \n",
       "9   {'tag': 'AE', 'spans': [[46, 54]], 'text': 'Ar...   \n",
       "10  {'tag': 'AE', 'spans': [[56, 72]], 'text': 'le...   \n",
       "11  {'tag': 'AE', 'spans': [[110, 114]], 'text': '...   \n",
       "12  {'tag': 'AE', 'spans': [[2221, 2229]], 'text':...   \n",
       "13  {'tag': 'AE', 'spans': [[3713, 3721]], 'text':...   \n",
       "14  {'tag': 'AE', 'spans': [[4325, 4341]], 'text':...   \n",
       "15  {'tag': 'AE', 'spans': [[4343, 4350]], 'text':...   \n",
       "16  {'tag': 'AE', 'spans': [[4352, 4360]], 'text':...   \n",
       "17  {'tag': 'AE', 'spans': [[5416, 5424]], 'text':...   \n",
       "18  {'tag': 'AE', 'spans': [[5510, 5518]], 'text':...   \n",
       "\n",
       "                                                 SVRT  \\\n",
       "0   {'tag': 'SVRT', 'spans': [[684, 688]], 'text':...   \n",
       "1   {'tag': 'SVRT', 'spans': [[1206, 1210]], 'text...   \n",
       "2   {'tag': 'SVRT', 'spans': [[691, 695]], 'text':...   \n",
       "3   {'tag': 'SVRT', 'spans': [[784, 791]], 'text':...   \n",
       "4   {'tag': 'SVRT', 'spans': [[1033, 1043]], 'text...   \n",
       "5   {'tag': 'SVRT', 'spans': [[961, 971]], 'text':...   \n",
       "6   {'tag': 'SVRT', 'spans': [[1033, 1043]], 'text...   \n",
       "7   {'tag': 'SVRT', 'spans': [[961, 971]], 'text':...   \n",
       "8   {'tag': 'SVRT', 'spans': [[1784, 1788]], 'text...   \n",
       "9   {'tag': 'SVRT', 'spans': [[118, 127]], 'text':...   \n",
       "10  {'tag': 'SVRT', 'spans': [[118, 127]], 'text':...   \n",
       "11  {'tag': 'SVRT', 'spans': [[118, 127]], 'text':...   \n",
       "12  {'tag': 'SVRT', 'spans': [[2209, 2220]], 'text...   \n",
       "13  {'tag': 'SVRT', 'spans': [[3706, 3712]], 'text...   \n",
       "14  {'tag': 'SVRT', 'spans': [[4381, 4400]], 'text...   \n",
       "15  {'tag': 'SVRT', 'spans': [[4381, 4400]], 'text...   \n",
       "16  {'tag': 'SVRT', 'spans': [[4381, 4400]], 'text...   \n",
       "17  {'tag': 'SVRT', 'spans': [[5411, 5415]], 'text...   \n",
       "18  {'tag': 'SVRT', 'spans': [[5503, 5509]], 'text...   \n",
       "\n",
       "                                             sentence  \\\n",
       "0   On 28Jan2021 18:30, the patient experienced mi...   \n",
       "1   The day after the arm was very sore, red and b...   \n",
       "2   The consumer reported receiving her first inje...   \n",
       "3   The consumer reports the pain was similar to w...   \n",
       "4   The consumer reported when she was told by peo...   \n",
       "5   The consumer reported when she was told by peo...   \n",
       "6   The consumer reported when she was told by peo...   \n",
       "7   The consumer reported when she was told by peo...   \n",
       "8   The outcome of the event mild pain at the site...   \n",
       "9   4/10/21 Patient presented to Urgent Care with ...   \n",
       "10  4/10/21 Patient presented to Urgent Care with ...   \n",
       "11  4/10/21 Patient presented to Urgent Care with ...   \n",
       "12  She has a very slight headache which has been ...   \n",
       "13  She also reported a slight headache that was p...   \n",
       "14  Regarding the left breast lump, redness, swell...   \n",
       "15  Regarding the left breast lump, redness, swell...   \n",
       "16  Regarding the left breast lump, redness, swell...   \n",
       "17  Her mild headache continues since the vaccine ...   \n",
       "18  She denies worsening or severe headache; denie...   \n",
       "\n",
       "                                               tokens  ann_idx  y  \n",
       "0   [On, 28Jan2021, 18:30, ,, the, patient, experi...        0  1  \n",
       "1   [The, day, after, the, arm, was, very, sore, ,...        1  1  \n",
       "2   [The, consumer, reported, receiving, her, firs...        2  1  \n",
       "3   [The, consumer, reports, the, pain, was, simil...        2  1  \n",
       "4   [The, consumer, reported, when, she, was, told...        2  0  \n",
       "5   [The, consumer, reported, when, she, was, told...        2  0  \n",
       "6   [The, consumer, reported, when, she, was, told...        2  0  \n",
       "7   [The, consumer, reported, when, she, was, told...        2  0  \n",
       "8   [The, outcome, of, the, event, mild, pain, at,...        2  1  \n",
       "9   [4/10/21, Patient, presented, to, Urgent, Care...        3  0  \n",
       "10  [4/10/21, Patient, presented, to, Urgent, Care...        3  0  \n",
       "11  [4/10/21, Patient, presented, to, Urgent, Care...        3  0  \n",
       "12  [She, has, a, very, slight, headache, which, h...        3  0  \n",
       "13  [She, also, reported, a, slight, headache, tha...        3  1  \n",
       "14  [Regarding, the, left, breast, lump, ,, rednes...        3  0  \n",
       "15  [Regarding, the, left, breast, lump, ,, rednes...        3  0  \n",
       "16  [Regarding, the, left, breast, lump, ,, rednes...        3  0  \n",
       "17  [Her, mild, headache, continues, since, the, v...        3  1  \n",
       "18  [She, denies, worsening, or, severe, headache,...        3  1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = []\n",
    "\n",
    "# the prop prefix for the Adverse Event and Severity\n",
    "prop_AE = 'link_AE'\n",
    "prop_SVRT = 'link_SVRT'\n",
    "\n",
    "for ann_idx, (ann_sent, ann) in enumerate(zip(ann_sents, rst['anns'])):\n",
    "    # ok, for each annotation file, \n",
    "    # we want to extract the annotated relations for positive training dataset\n",
    "    # there can be multiple sentence in a file, \n",
    "    # so we need to check each sentence\n",
    "    for sentag in ann_sent['sentence_tags']:\n",
    "        if len(sentag['relations'])==0:\n",
    "            # Oh, this sentence doesn't have a relation annotated\n",
    "            # but we can use this sentence for building negative samples\n",
    "            # as the SVRT tags and AE tags have no relations\n",
    "            # this is just a demo, please change it accordingly.\n",
    "            stags_ae = []\n",
    "            stags_svrt = []\n",
    "            for tag in sentag['entities'].values():\n",
    "                if tag['tag'] == 'AE': stags_ae.append(tag)\n",
    "                elif tag['tag'] == 'SVRT': stags_svrt.append(tag)\n",
    "            # let's check how many tags \n",
    "            # but if not AE or SVRT tags, we just skip\n",
    "            if len(stags_ae)==0 or len(stags_svrt)==0: continue\n",
    "\n",
    "            # OK, pair each ae and svrt as NEGATIVE sample\n",
    "            for _tag_a in stags_ae:\n",
    "                for _tag_s in stags_svrt:\n",
    "                    # create a data item\n",
    "                    d = {\n",
    "                        \"AE\": _tag_a,\n",
    "                        \"SVRT\": _tag_s,\n",
    "                        \"sentence\": sentag['sentence'],\n",
    "                        \"tokens\": sentag['sentence_tokens'],\n",
    "                        \"ann_idx\": ann_idx,\n",
    "                        \"y\": 0, # for those obtained by creating, define as 0\n",
    "                    }\n",
    "\n",
    "                    ds.append(d)\n",
    "\n",
    "        else:\n",
    "            # Ok, this sentence may have several relations\n",
    "            # let's check one by one\n",
    "            for rel in sentag['relations'].values():\n",
    "                # get the AE\n",
    "                ent_ae = sentag['entities'][rel['%sID' % prop_AE]]\n",
    "                ent_svrt = sentag['entities'][rel['%sID' % prop_SVRT]]\n",
    "\n",
    "                # ok, we can save this relation now\n",
    "                d = {\n",
    "                    \"AE\": ent_ae,\n",
    "                    \"SVRT\": ent_svrt,\n",
    "                    \"sentence\": sentag['sentence'],\n",
    "                    \"tokens\": sentag['sentence_tokens'],\n",
    "                    \"ann_idx\": ann_idx,\n",
    "                    \"y\": 1, # for those obtained from relation, define as 1(POSITIVE)\n",
    "                }\n",
    "\n",
    "                ds.append(d)\n",
    "\n",
    "df = pd.DataFrame(ds)\n",
    "print('* got the dataset %d records!' % (len(df)))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train/test\n",
    "As you can see, a very tiny dataset is created with both positive and negative samples. And we preserved as much information as possible in the dataframe to generate features. \n",
    "\n",
    "In practice settings, you don't need to save those raw data into a dataframe. Instead, you can just save major information, such as token, index, sentences, which can reduce the space needed for large corpus.\n",
    "\n",
    "You can save this dataset into `pkl` format for futuer usage as follows or any other formats.\n",
    "\n",
    "```Python\n",
    "import pickle\n",
    "\n",
    "with open('dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "```\n",
    "\n",
    "In future, you can load the dataset as follows:\n",
    "\n",
    "```Python\n",
    "with open('dataset.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "```\n",
    "\n",
    "Now, let's get the training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random select 80% for training\n",
    "df_train = df.sample(frac=0.8)\n",
    "# the rest 20% for test\n",
    "df_test = df.iloc[~df.index.isin(df_train.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features\n",
    "\n",
    "Although we have got all the information needed, we still need to convert the information to features which can be read by machine.\n",
    "\n",
    "There are so many methods to convert, simple and complex. You will never know which one is the best if you don't try and understand the pros and cons of each method. For this demo purpose, we just show a very simple way: \n",
    "\n",
    "In practice settings, you may choose BERT-based models to get text embeddings of the tokens, POS features, and other knowledge graph embeddings to fully capture the information. We plan to include more practical demos to show how to do that in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPy37",
   "language": "python",
   "name": "nlpy37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
